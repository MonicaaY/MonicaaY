# -*- coding: utf-8 -*-
"""Sentiment analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XEAKXDWThcfOaIwX2t-HllPrlKj6GCOc
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

st = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/amazon_alexa.tsv', sep = '\t')

st.head(10)

st.tail(10)

st.info()

sns.pairplot(st)

sns.scatterplot(st)

st['verified_reviews']

pos = st[st['feedback']==1]

pos

neg = st[st['feedback']==0]
neg

sns.countplot(st['feedback'], label = 'Count')

sns.countplot(x = 'rating', data = st)

st['rating'].hist(bins = 5)

plt.figure(figsize = (40,15))
sns.barplot(x = 'variation', y = 'rating', data = st, palette = 'deep')

plt.scatter(st.variation, st.rating, color = 'violet')

st = st.drop(labels = {'rating', 'date'}, axis =1)

st

variations_dummies = pd.get_dummies(st['variation'], drop_first = True)

variations_dummies

st.drop(['variation'],axis = 1, inplace = True)

st

st = pd.concat([st, variations_dummies], axis = 1)

st

from sklearn.feature_extraction.text import CountVectorizer
sample_data = ['This is the first document.','This is the second document.','And this is  the third one.','Is this the first document?']
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(sample_data)

X

print(X.toarray())

print(vectorizer.get_feature_names_out())

vectorizer = CountVectorizer()
alexa_cv = vectorizer.fit_transform(st['verified_reviews'])

alexa_cv.shape

print(vectorizer.get_feature_names_out())

print(alexa_cv.toarray())

st.drop(['verified_reviews'], axis = 1, inplace = True)

reviews = pd.DataFrame(alexa_cv.toarray())

st = pd.concat([st, reviews], axis = 1)

st

X = st.drop(labels = {'feedback'}, axis = 1)

y = st['feedback']

y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2)

X_train.shape

y_train.shape

X_test.shape

y_test.shape

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(units = 100, activation = 'relu', input_shape = (4059,)))
model.add(tf.keras.layers.Dense(units = 10, activation = 'relu'))
model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))
model.summary()

model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

epoch_hist = model.fit(X_train, y_train, epochs = 10)

evaluation = model.evaluate(X_test, y_test)
print('test_accuracy:{}'.format(evaluation[1]))

epoch_hist.history.keys()

eh = epoch_hist.history['loss']
eh2 = epoch_hist.history['accuracy']
plt.plot(eh)
plt.plot(eh2)
plt.title('Variation of loss and accuracy with respect to number of epochs')
plt.xlabel('epochs')
plt.ylabel('Loss and accuracy with respect to epochs')

y_predict = model.predict(X_test)

y_predict

y_predict = (y_predict > 0.5)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_predict, y_test)
sns.heatmap(cm, annot = True)

y_train_pred = model.predict(X_train)

y_train_pred = (y_train_pred  > 0.5)

cm2 = confusion_matrix(y_train_pred, y_train)

cm2

sns.heatmap(cm2, annot = True)

from sklearn.metrics import classification_report
classification_Report = classification_report(y_train_pred, y_train)
print(classification_Report)

from sklearn.metrics import classification_report
classification_Report = classification_report(y_predict, y_test)
print(classification_Report)
